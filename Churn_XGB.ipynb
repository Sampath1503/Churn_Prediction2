{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnGA6ln9VoAd",
        "outputId": "81cff4dd-f6df-4e8d-a162-5daf98a76035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1971731295.py:20: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df.replace(['Nan', 'nan', 'NaN', 'NAN'], np.nan, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [11:38:40] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best XGBoost Params: {'subsample': 1.0, 'reg_lambda': 1, 'reg_alpha': 0, 'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.05, 'gamma': 0.2, 'colsample_bytree': 0.7}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          no       0.98      1.00      0.99       859\n",
            "         yes       0.98      0.87      0.92       141\n",
            "\n",
            "    accuracy                           0.98      1000\n",
            "   macro avg       0.98      0.93      0.95      1000\n",
            "weighted avg       0.98      0.98      0.98      1000\n",
            "\n",
            "[[856   3]\n",
            " [ 19 122]]\n",
            "‚úÖ Saved: num_imputer.pkl, cat_imputer.pkl, encoder.pkl, scaler.pkl, xgb_model.pkl\n"
          ]
        }
      ],
      "source": [
        "# -----------------------------\n",
        "# 1Ô∏è‚É£ Imports\n",
        "# -----------------------------\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.combine import SMOTETomek  # The best-performing sampler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import joblib\n",
        "\n",
        "# -----------------------------\n",
        "# 2Ô∏è‚É£ Load Dataset & Feature Engineering\n",
        "# -----------------------------\n",
        "df = pd.read_excel(\"P585 Churn.xlsx\")\n",
        "\n",
        "df.columns = df.columns.str.strip()\n",
        "df.replace(['Nan', 'nan', 'NaN', 'NAN'], np.nan, inplace=True)\n",
        "df.drop(columns=['Unnamed: 0'], errors='ignore', inplace=True)\n",
        "\n",
        "# Create 'value' features\n",
        "df['total_charge'] = df['day.charge'] + df['eve.charge'] + df['night.charge'] + df['intl.charge']\n",
        "df['total_mins'] = df['day.mins'] + df['eve.mins'] + df['night.mins'] + df['intl.mins']\n",
        "df['charge_per_min'] = df['total_charge'] / (df['total_mins'] + 1e-6)\n",
        "\n",
        "# Create 'usage' features\n",
        "df['total_calls'] = df['day.calls'] + df['eve.calls'] + df['night.calls'] + df['intl.calls']\n",
        "df['mins_per_call'] = df['total_mins'] / (df['total_calls'] + 1e-6)\n",
        "\n",
        "# Bin the 'customer.calls' feature\n",
        "def get_service_call_bin(calls):\n",
        "    if calls == 0:\n",
        "        return '0_calls'\n",
        "    elif calls <= 3:\n",
        "        return '1-3_calls'\n",
        "    else:\n",
        "        return '4+_calls'\n",
        "\n",
        "df['service_call_bin'] = df['customer.calls'].apply(get_service_call_bin)\n",
        "\n",
        "# Create the \"Pay-As-You-Go International\" pain feature\n",
        "df['pay_as_you_go_intl'] = (\n",
        "    (df['intl.plan'] == 'no') & (df['intl.mins'] > 0)\n",
        ").astype(int)\n",
        "\n",
        "# -----------------------------\n",
        "# 3Ô∏è‚É£ Feature & Target\n",
        "# -----------------------------\n",
        "X = df.drop('churn', axis=1)\n",
        "y = df['churn']\n",
        "\n",
        "# -----------------------------\n",
        "# 4Ô∏è‚É£ Train-Test Split\n",
        "# -----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 5Ô∏è‚É£ Impute + Encode\n",
        "# -----------------------------\n",
        "categorical_cols = ['state', 'voice.plan', 'intl.plan', 'service_call_bin']\n",
        "numeric_cols = X_train.select_dtypes(include=np.number).columns\n",
        "\n",
        "num_imputer = SimpleImputer(strategy='median')\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "\n",
        "X_train_num = num_imputer.fit_transform(X_train[numeric_cols])\n",
        "X_test_num = num_imputer.transform(X_test[numeric_cols])\n",
        "\n",
        "X_train_cat = cat_imputer.fit_transform(X_train[categorical_cols])\n",
        "X_test_cat = cat_imputer.transform(X_test[categorical_cols])\n",
        "\n",
        "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
        "X_train_enc = ohe.fit_transform(X_train_cat)\n",
        "X_test_enc = ohe.transform(X_test_cat)\n",
        "\n",
        "X_train_final = np.hstack([X_train_num, X_train_enc])\n",
        "X_test_final = np.hstack([X_test_num, X_test_enc])\n",
        "\n",
        "# -----------------------------\n",
        "# 6Ô∏è‚É£ Scaling\n",
        "# -----------------------------\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_final)\n",
        "X_test_scaled = scaler.transform(X_test_final)\n",
        "\n",
        "# -----------------------------\n",
        "# 7Ô∏è‚É£ Resampling with SMOTETomek\n",
        "# -----------------------------\n",
        "smote_tomek = SMOTETomek(random_state=42)\n",
        "X_res, y_res = smote_tomek.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "# -----------------------------\n",
        "# 8Ô∏è‚É£ XGBoost Model + RandomizedSearch\n",
        "# -----------------------------\n",
        "y_res_encoded = (y_res == 'yes').astype(int)\n",
        "y_test_encoded = (y_test == 'yes').astype(int)\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [200, 300],\n",
        "    'max_depth': [6, 7, 8],\n",
        "    'learning_rate': [0.1, 0.05],\n",
        "    'subsample': [0.7, 1.0],\n",
        "    'colsample_bytree': [0.7, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'reg_alpha': [0, 0.1],\n",
        "    'reg_lambda': [1, 1.5]\n",
        "}\n",
        "\n",
        "# Use RandomizedSearchCV\n",
        "grid_search_xgb = RandomizedSearchCV(\n",
        "    estimator=XGBClassifier(\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss',\n",
        "        random_state=42\n",
        "    ),\n",
        "    param_distributions=param_grid_xgb,\n",
        "    n_iter=50,  # Try 50 random combinations\n",
        "    scoring='f1',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Fit on the resampled data\n",
        "grid_search_xgb.fit(X_res, y_res_encoded)\n",
        "\n",
        "print(\"Best XGBoost Params:\", grid_search_xgb.best_params_)\n",
        "\n",
        "# Use the BEST model found by the search\n",
        "xgb_model = grid_search_xgb.best_estimator_\n",
        "\n",
        "# -----------------------------\n",
        "# 9Ô∏è‚É£ Threshold Prediction Function\n",
        "# -----------------------------\n",
        "def predict_with_threshold(model, X, threshold=0.5):\n",
        "    probs = model.predict_proba(X)[:, 1]\n",
        "    pred = np.where(probs >= threshold, 'yes', 'no')\n",
        "    return pred\n",
        "\n",
        "# -----------------------------\n",
        "# üîü Final Evaluation on XGBoost\n",
        "# -----------------------------\n",
        "y_pred = predict_with_threshold(xgb_model, X_test_scaled, threshold=0.5)\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "# -----------------------------\n",
        "# 1Ô∏è‚É£1Ô∏è‚É£ Save Artifacts for Deployment\n",
        "# -----------------------------\n",
        "joblib.dump(num_imputer, \"num_imputer.pkl\")\n",
        "joblib.dump(cat_imputer, \"cat_imputer.pkl\")\n",
        "joblib.dump(ohe, \"encoder.pkl\")\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "joblib.dump(xgb_model, \"xgb_model.pkl\") # Save the best model\n",
        "\n",
        "print(\"‚úÖ Saved: num_imputer.pkl, cat_imputer.pkl, encoder.pkl, scaler.pkl, xgb_model.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YVsUl4XZAyuv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
